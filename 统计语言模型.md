# 统计语言模型

## 语言模型概念

任何一个自然语言文本都可以看成词表 
$$
V = {w_1, w_2, ...,  w_{|V|}}
$$


下采样生成的单词序列；语言模型的核心是确定此序列 
$$
W = {w_1, w_2, ..., w_n}
$$
的概率，该概率可以表达为：
$$
P(W) = P(w_1)* p(w_2|w_1) * ··· * P(w_m|w_1w_2···w_{m-1})
$$


## 语言模型评价

语言模型评价最常见的指标是Perplexity 中文一般叫做困惑度。 当模型训练好后， 给定一个测试语料集：
$$
D_t = {W_1, W_2, ..., W_N}
$$
困惑度计算如下：
$$
PPL = exp(-\frac{1}{N_t}\sum_{W_i \in D_t}LogP(W_i))
$$


困惑度可以度量一个概率模型适配数据的能力， 更低的困惑度意味着更好的数据适配能力。 



## N-gram概率计算

在用最大似然估计法来进行模型的参数估计时， 可以得到最大化的参数是每个n元单词的频数 除以所以单词的频数， 具体数学公式如下：
$$
P^* = arg  max \sum_{k=1}^{|D|}logP(W_k)
$$

$$
P(w_i|w_1, w_2, ···， w_{i-1}) = \frac{\#(w_1, w2 ··· w_{i-1}, w_{i})}{\sum_{w_j\in V}\#(w_{1}w_{2}···w_{i-1}w_{j})}
$$

统计语言模型面临严重的 零概率问题。为此研究者提出了一系列的平滑手段解决这个问题。

### 平滑技术

#### 加法平均

假设每个词出现的次数比实际观察的多x 次， 0 < x < 1, 则公式如下：
$$
P_{add}(w_n|w_1w_2··· w_{n-1}) = \frac{x+\#(w_1w_2 ···w_{n-1}w_n)}{x * |V| + \sum_{w_j \in V }\#(w_1w_2···w_{n-1}w_j)}
$$


#### Good-Turing 估计

这个是许多平滑技术的核心， 基本思路是， 对于任何一个出现r次的

#### Katz平滑

#### Kneser-Ney平滑

